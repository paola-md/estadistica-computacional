---
title: "R Notebook"
output: html_notebook
---


```{r}
library(usethis)
dir.create("data")
use_directory("data")
use_zip("https://d396qusza40orc.cloudfront.net/rprog%2Fdata%2Fspecdata.zip", 
    destdir = "data")
```

Crea un vector con las direcciones de los archivos.

```{r}
paths <- dir("data/specdata", pattern = "\\.csv$", full.names = TRUE)
```

Lee uno de los archivos usando la función read_csv() del paquete readr.
Tip: especifica el tipo de cada columna usando el parámetro col_types.
```{r}
library(readr)
prueba <- read_csv(paths[1], col_types = list(
  Date = col_date(format = ""),
  sulfate = col_double(),
  nitrate = col_double(),
  ID = col_double()
))
prueba

```


```{r}
library(purrr)
rama <- map_df(paths, read_csv, .id = "FILENAME")
```

```{r}
head(rama)
```

### Pregunta 2
Consideramos los datos de ENLACE edo. de México (enlace), y la columna de calificaciones de español 3o de primaria (esp_3).

```{r}
library(estcomp)
library(janitor)
library(dplyr)

enlace <- enlacep_2013 %>% 
    clean_names() %>% 
    mutate(id = 1:n()) %>% 
    select(id, cve_ent, turno, tipo, esp_3 = punt_esp_3, esp_6 = punt_esp_6, 
        n_eval_3 = alum_eval_3, n_eval_6 = alum_eval_6) %>% 
    na.omit() %>% 
    filter(esp_3 > 0, esp_6 > 0, n_eval_3 > 0, n_eval_6 > 0, cve_ent == "15")
```
Selecciona una muestra de tamaño  
n =10, 100, 1000
Para cada muestra calcula media y el error estándar de la media usando el principio del plug-in: 
Tip: Usa la función sample_n() del paquete deplyr para generar las muestras.
```{r}
plug_in <- function(enlace, esp_3, n) {
  enlace %>% summarise(
    media = mean(esp_3, na.rm = TRUE),
    se = sqrt(sd(esp_3 , na.rm = TRUE) / n)
  )
}
```


```{r}
set.seed(16021)

# muestra
enlace_10 <- sample_n(enlace, 10)
enlace_100 <- sample_n(enlace, 100)
enlace_1000 <- sample_n(enlace, 1000)

est10 <- plug_in(enlace_10, esp_3, 10)
est100 <- plug_in(enlace_100, esp_3, 100)
est1000 <-plug_in(enlace_1000, esp_3, 1000)

```

Ahora aproximareos la distribución muestral, para cada tamaño de muestra  
n
La distribución de la estadística es la distribución muestral.

```{r}
ggplot() +
  stat_function(data = enlace_10, aes(enlace_10$esp_3), fun = dnorm, n = 10, args = list(mean = est10[[1]], sd = est10[[2]])) + ylab("") 

ggplot() +
    stat_function(data = enlace_100, aes(enlace_100$esp_3), fun = dnorm, n = 100, args = list(mean = est100[[1]], sd = est100[[2]])) + ylab("") 
  
 ggplot() +
    stat_function(data = enlace_1000, aes(enlace_1000$esp_3), fun = dnorm, n = 100, args = list(mean = est1000[[1]], sd = est1000[[2]])) + ylab("") 
```

Simula  10,000 muestras aleatorias, ii) calcula la media en cada muestra,

```{r}
simula_media <- function(n, x) {
  muestra_boot <- sample(x, size = n, replace = TRUE)
  mean(muestra_boot, na.rm = TRUE)
}

medias_10 <- rerun(10000, simula_media(n = 10, enlace$esp_3)) %>% flatten_dbl()
medias_100 <- rerun(10000, simula_media(n = 100, enlace$esp_3)) %>% flatten_dbl()
medias_1000 <- rerun(10000, simula_media(n = 1000, enlace$esp_3)) %>% flatten_dbl()

```

Realiza un histograma de la distribución muestral de las medias (las medias del paso anterior) 

```{r}

```



iv) aproxima el error estándar calculando la desviación estándar de las medias del paso ii. Tip: Escribe una función que dependa del tamaño de muestra y usa la función rerun() del paquete purrr para hacer las  10,000   simulaciones.

```{r}
simula_media <- function(n, x) {
  muestra_boot <- sample(x, size = n, replace = TRUE)
  mean(muestra_boot, na.rm = TRUE)
}

medias_10 <- rerun(10000, simula_media(n = 10, enlace$esp_3)) %>% flatten_dbl()
medias_100 <- rerun(10000, simula_media(n = 100, enlace$esp_3)) %>% flatten_dbl()
medias_1000 <- rerun(10000, simula_media(n = 1000, enlace$esp_3)) %>% flatten_dbl()

```


Calcula el error estándar de la media para cada tamaño de muestra usando la información poblacional (ésta no es una aproximación), usa la fórmula:

```{r}

```




¿Cómo se comparan los errores estándar correspondientes a los distintos tamaños de muestra?